<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>gojo.deepl.models &mdash; gojo - Documentation 0.1.4 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #F24C4C" >
            <a href="../../../index.html" class="icon icon-home"> gojo - Documentation
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Hands-on</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Example_1_Model_evaluation_by_cross_validation.html">Model evaluation by cross validation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/Example_1_Model_evaluation_by_cross_validation.html#definition-and-evaluation-of-a-support-vector-machine-svm-model"><strong>Definition and evaluation of a Support Vector Machine (SVM) model</strong></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Example_1_Model_evaluation_by_cross_validation.html#understanding-svms-with-polynomial-kernels"><strong>Understanding SVMs with Polynomial Kernels</strong></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../examples/Example_1_Model_evaluation_by_cross_validation.html#introduction-to-svm"><strong>Introduction to SVM</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../examples/Example_1_Model_evaluation_by_cross_validation.html#the-mathematical-foundation-hyperplane"><strong>The Mathematical Foundation - Hyperplane</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../examples/Example_1_Model_evaluation_by_cross_validation.html#the-mathematical-foundation-maximizing-the-margin"><strong>The Mathematical Foundation - Maximizing the Margin</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../examples/Example_1_Model_evaluation_by_cross_validation.html#the-mathematical-foundation-the-optimization-problem"><strong>The Mathematical Foundation - The Optimization Problem</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../examples/Example_1_Model_evaluation_by_cross_validation.html#the-mathematical-foundation-introducing-kernels"><strong>The Mathematical Foundation - Introducing Kernels</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Example_1_Model_evaluation_by_cross_validation.html#hands-on"><strong>Hands-on</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Example_2_Neural_networks_integration.html">Neural networks integration</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/Example_2_Neural_networks_integration.html#basic-model-training">Basic model training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/Example_2_Neural_networks_integration.html#model-evaluation-via-cross-validation">Model evaluation via cross-validation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Example_3_Hyperparameter_optimization_by_nested_cross_validation.html">Hyperparameter optimization by nested cross-validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Example_3_Hyperparameter_optimization_by_nested_cross_validation.html#initial-model-evaluation">Initial model evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Example_3_Hyperparameter_optimization_by_nested_cross_validation.html#hyperparameter-optimization">Hyperparameter optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Example_4_Vanilla_Variational_Autoencoder.html">Vanilla Variational Autoencoder (vVAE)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/Example_4_Vanilla_Variational_Autoencoder.html#data-loading">Data loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/Example_4_Vanilla_Variational_Autoencoder.html#model-training">Model training</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Example_4_Vanilla_Variational_Autoencoder.html#model-convergence">Model convergence</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/Example_4_Vanilla_Variational_Autoencoder.html#model-evaluation">Model evaluation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Example_4_Vanilla_Variational_Autoencoder.html#analyze-the-reconstruction-error">Analyze the reconstruction error</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Example_4_Vanilla_Variational_Autoencoder.html#compute-regression-metrics">Compute regression metrics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Example_4_Vanilla_Variational_Autoencoder.html#visualize-embedding-dimensions">Visualize embedding dimensions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Example_4_Vanilla_Variational_Autoencoder.html#generate-samples">Generate samples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Example_5_Testing_different_CNN_architectures.html">Example 6. Testing different CNN architectures</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/Example_5_Testing_different_CNN_architectures.html#data-loading">Data loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/Example_5_Testing_different_CNN_architectures.html#vanilla-cnn">Vanilla CNN</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Example_5_Testing_different_CNN_architectures.html#model-convergence">Model convergence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Example_5_Testing_different_CNN_architectures.html#model-evaluation">Model evaluation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/Example_5_Testing_different_CNN_architectures.html#cnn-with-residual-connections">CNN with residual connections</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Example_5_Testing_different_CNN_architectures.html#id1">Model convergence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../examples/Example_5_Testing_different_CNN_architectures.html#id2">Model evaluation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/Advanced_use.html">Advanced use</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/Advanced_use.html#definition-of-your-own-transformations-gojo-interfaces-transform">Definition of your own transformations (gojo.interfaces.Transform)</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../gojo.core.html">gojo.core package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.core.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.core.html#module-gojo.core.evaluation">gojo.core.evaluation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.core.html#module-gojo.core.loops">gojo.core.loops module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.core.html#module-gojo.core.report">gojo.core.report module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.core.html#module-gojo.core">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../gojo.interfaces.html">gojo.interfaces package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.interfaces.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.interfaces.html#module-gojo.interfaces.model">gojo.interfaces.model module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.interfaces.html#module-gojo.interfaces.data">gojo.interfaces.data module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.interfaces.html#module-gojo.interfaces.transform">gojo.interfaces.transform module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.interfaces.html#module-gojo.interfaces">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../gojo.deepl.html">gojo.deepl package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.deepl.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.deepl.html#module-gojo.deepl.callback">gojo.deepl.callback module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.deepl.html#module-gojo.deepl.cnn">gojo.deepl.cnn module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.deepl.html#module-gojo.deepl.ffn">gojo.deepl.ffn module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.deepl.html#module-gojo.deepl.loading">gojo.deepl.loading module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.deepl.html#module-gojo.deepl.loops">gojo.deepl.loops module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.deepl.html#module-gojo.deepl.loss">gojo.deepl.loss module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.deepl.html#module-gojo.deepl.models">gojo.deepl.models module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.deepl.html#module-gojo.deepl">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../gojo.plotting.html">gojo.plotting package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.plotting.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.plotting.html#module-gojo.plotting.basic">gojo.plotting.basic module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.plotting.html#module-gojo.plotting.classification">gojo.plotting.classification module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.plotting.html#module-gojo.plotting">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../gojo.util.html">gojo.util package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.util.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.util.html#module-gojo.util.io">gojo.util.io module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.util.html#module-gojo.util.login">gojo.util.login module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.util.html#module-gojo.util.splitter">gojo.util.splitter module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.util.html#module-gojo.util.tools">gojo.util.tools module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.util.html#module-gojo.util.validation">gojo.util.validation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.util.html#module-gojo.util">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../gojo.experimental.html">gojo.experimental package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../gojo.experimental.html#module-gojo.experimental">Module contents</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #F24C4C" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">gojo - Documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../../index.html">Module code</a> &raquo;</li>
      <li>gojo.deepl.models</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for gojo.deepl.models</h1><div class="highlight"><pre>
<span></span><span class="c1"># Module with common neural network architectures.</span>
<span class="c1">#</span>
<span class="c1"># Author: Fernando García Gutiérrez</span>
<span class="c1"># Email: fgarcia@fundacioace.org</span>
<span class="c1">#</span>
<span class="c1"># STATUS: completed, functional, and documented.</span>
<span class="c1">#</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch_geometric</span> <span class="k">as</span> <span class="nn">geom</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span>

<span class="kn">from</span> <span class="nn">.ffn</span> <span class="kn">import</span> <span class="n">createSimpleFFNModel</span>
<span class="kn">from</span> <span class="nn">..util.validation</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">checkMultiInputTypes</span><span class="p">,</span>
    <span class="n">checkInputType</span><span class="p">,</span>
    <span class="n">checkCallable</span>
<span class="p">)</span>


<div class="viewcode-block" id="MultiTaskFFN"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.MultiTaskFFN">[docs]</a><span class="k">class</span> <span class="nc">MultiTaskFFN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Model adapted to perform multi-task classification with a layer specialized in extracting features (accessible</span>
<span class="sd">    through :meth:`feature_extractor`) and, as is typical in multi-task model training, layers specialized in</span>
<span class="sd">    performing the different tasks. The model will return a tensor with the outputs of each of the layers</span>
<span class="sd">    concatenated, where the first `n_clf_task` classification tasks will go first, followed by the `n_reg_task`</span>
<span class="sd">    regression tasks.</span>


<span class="sd">    Parameters</span>
<span class="sd">    -----------</span>

<span class="sd">    in_feats : int</span>
<span class="sd">        (feature extractor) Number of input features.</span>

<span class="sd">    emb_feats : int</span>
<span class="sd">        (feature extractor) Number of output features for the feature extractor feed forward network (FFN).</span>

<span class="sd">    layer_dims : list</span>
<span class="sd">        (feature extractor) Layer dims for the feature extractor feed forward network (FFN).</span>

<span class="sd">    n_clf_task : int</span>
<span class="sd">        (feature extractor) Number of classification task. If `n_clf_task` = 0, then `n_reg_task` must be greater</span>
<span class="sd">        than 1.</span>

<span class="sd">    n_reg_task : int</span>
<span class="sd">        (feature extractor) Number of regression task. If `n_reg_task` = 0, then `n_clf_task` must be greater than 1.</span>

<span class="sd">    multt_layer_dims : list</span>
<span class="sd">        (multi-task layers) Architecture used for the task&#39;s specialized layers.</span>

<span class="sd">    multt_dropout : list or float, default=None</span>
<span class="sd">        (multi-task layers) Dropout for the task&#39;s specialized layers.</span>

<span class="sd">    multt_layer_activation : torch.nn.Module or str or None, default=&#39;ELU&#39;</span>
<span class="sd">        (multi-task layers) Activation function for the task&#39;s specialized layers.</span>

<span class="sd">    multt_batchnorm : bool, default=False</span>
<span class="sd">        (multi-task layers) Indicates whether to used batch normalization in the task&#39;s specialized layers.</span>

<span class="sd">    multt_clf_activation : str or torch.nn.Module or list or None, default=&#39;Sigmoid&#39;</span>
<span class="sd">        (multi-task layers, classification) Output activation function for the classification task. If a list is</span>
<span class="sd">        provided this must match the length of the parameter `n_clf_task`.</span>

<span class="sd">    multt_reg_activation : str or torch.nn.Module or list or None, default=None</span>
<span class="sd">        (multi-task layers, regression) Output activation function for the regression task. If a list is provided this</span>
<span class="sd">        must match the length of the parameter `n_reg_task`.</span>

<span class="sd">    layer_dropout : list or float or None, default=None</span>
<span class="sd">        (feature extractor) Dropout rate for the feature extractor feed forward network (FFN).</span>

<span class="sd">    layer_activation : torch.nn.Module or str or None, default=&#39;ELU&#39;</span>
<span class="sd">        (feature extractor) Activation function for the feature extractor feed forward network (FFN).</span>

<span class="sd">    batchnorm : bool, default=False</span>
<span class="sd">        (feature extractor param)Indicates whether to used batch normalization in the feature extractor feed forward</span>
<span class="sd">        network (FFN).</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from gojo import deepl</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; model = deepl.models.MultiTaskFFN(</span>
<span class="sd">    &gt;&gt;&gt;     in_feats=100,</span>
<span class="sd">    &gt;&gt;&gt;     emb_feats=20,</span>
<span class="sd">    &gt;&gt;&gt;     layer_dims=[250, 50],</span>
<span class="sd">    &gt;&gt;&gt;     n_clf_task=2,</span>
<span class="sd">    &gt;&gt;&gt;     n_reg_task=3,</span>
<span class="sd">    &gt;&gt;&gt;     multt_layer_dims=[20, 10],</span>
<span class="sd">    &gt;&gt;&gt;     multt_dropout=0.2,</span>
<span class="sd">    &gt;&gt;&gt;     multt_layer_activation=&#39;ELU&#39;,</span>
<span class="sd">    &gt;&gt;&gt;     multt_batchnorm=False,</span>
<span class="sd">    &gt;&gt;&gt;     multt_clf_activation=&#39;Sigmoid&#39;,</span>
<span class="sd">    &gt;&gt;&gt;     multt_reg_activation=[&#39;TanU&#39;, None, None],</span>
<span class="sd">    &gt;&gt;&gt;     layer_dropout=0.4,</span>
<span class="sd">    &gt;&gt;&gt;     layer_activation=&#39;ELU&#39;,</span>
<span class="sd">    &gt;&gt;&gt;     batchnorm=True</span>
<span class="sd">    &gt;&gt;&gt; )</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="c1"># feature extractor parameters</span>
            <span class="n">in_feats</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">emb_feats</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">layer_dims</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span>
            <span class="n">n_clf_task</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">n_reg_task</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>

            <span class="c1"># multi-task layers parameters</span>
            <span class="n">multt_layer_dims</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span>
            <span class="n">multt_dropout</span><span class="p">:</span> <span class="nb">list</span> <span class="ow">or</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">multt_layer_activation</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="ow">or</span> <span class="nb">str</span> <span class="ow">or</span> <span class="kc">None</span> <span class="o">=</span> <span class="s1">&#39;ELU&#39;</span><span class="p">,</span>
            <span class="n">multt_batchnorm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">multt_clf_activation</span><span class="p">:</span> <span class="nb">str</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="ow">or</span> <span class="nb">list</span> <span class="ow">or</span> <span class="kc">None</span> <span class="o">=</span> <span class="s1">&#39;Sigmoid&#39;</span><span class="p">,</span>
            <span class="n">multt_reg_activation</span><span class="p">:</span> <span class="nb">str</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="ow">or</span> <span class="nb">list</span> <span class="ow">or</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>

            <span class="c1"># other feature extractor parameters</span>
            <span class="n">layer_dropout</span><span class="p">:</span> <span class="nb">list</span> <span class="ow">or</span> <span class="nb">float</span> <span class="ow">or</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">layer_activation</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="ow">or</span> <span class="nb">str</span> <span class="ow">or</span> <span class="kc">None</span> <span class="o">=</span> <span class="s1">&#39;ELU&#39;</span><span class="p">,</span>
            <span class="n">batchnorm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiTaskFFN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># save input parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_feats</span> <span class="o">=</span> <span class="n">in_feats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb_feats</span> <span class="o">=</span> <span class="n">emb_feats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_clf_task</span> <span class="o">=</span> <span class="n">n_clf_task</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_reg_task</span> <span class="o">=</span> <span class="n">n_reg_task</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_dims</span> <span class="o">=</span> <span class="n">layer_dims</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multt_layer_dims</span> <span class="o">=</span> <span class="n">multt_layer_dims</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multt_dropout</span> <span class="o">=</span> <span class="n">multt_dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multt_layer_activation</span> <span class="o">=</span> <span class="n">multt_layer_activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multt_batchnorm</span> <span class="o">=</span> <span class="n">multt_batchnorm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multt_clf_activation</span> <span class="o">=</span> <span class="n">multt_clf_activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multt_reg_activation</span> <span class="o">=</span> <span class="n">multt_reg_activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_dropout</span> <span class="o">=</span> <span class="n">layer_dropout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer_activation</span> <span class="o">=</span> <span class="n">layer_activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batchnorm</span> <span class="o">=</span> <span class="n">batchnorm</span>

        <span class="c1"># check (and rearrange) input parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_checkModelParams</span><span class="p">()</span>

        <span class="c1"># create common layers (aka feature extractor)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span> <span class="o">=</span> <span class="n">createSimpleFFNModel</span><span class="p">(</span>
            <span class="n">in_feats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">in_feats</span><span class="p">,</span>
            <span class="n">out_feats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_feats</span><span class="p">,</span>
            <span class="n">layer_dims</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_dims</span><span class="p">,</span>
            <span class="n">layer_dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_dropout</span><span class="p">,</span>
            <span class="n">batchnorm</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batchnorm</span><span class="p">,</span>
            <span class="n">layer_activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">layer_activation</span><span class="p">,</span>
            <span class="n">output_activation</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="c1"># create multitask layers</span>
        <span class="c1"># -- classification layers</span>
        <span class="n">clf_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clf_task</span><span class="p">):</span>
            <span class="n">clf_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">createSimpleFFNModel</span><span class="p">(</span>
                    <span class="n">in_feats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_feats</span><span class="p">,</span>
                    <span class="n">out_feats</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">layer_dims</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_layer_dims</span><span class="p">,</span>
                    <span class="n">layer_dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_dropout</span><span class="p">,</span>
                    <span class="n">batchnorm</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_batchnorm</span><span class="p">,</span>
                    <span class="n">layer_activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_layer_activation</span><span class="p">,</span>
                    <span class="n">output_activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_clf_activation</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">clf_layers</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">clf_layers</span><span class="p">)</span>

        <span class="c1"># -- regression layers</span>
        <span class="n">reg_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_reg_task</span><span class="p">):</span>
            <span class="n">reg_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">createSimpleFFNModel</span><span class="p">(</span>
                    <span class="n">in_feats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">emb_feats</span><span class="p">,</span>
                    <span class="n">out_feats</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                    <span class="n">layer_dims</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_layer_dims</span><span class="p">,</span>
                    <span class="n">layer_dropout</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_dropout</span><span class="p">,</span>
                    <span class="n">batchnorm</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_batchnorm</span><span class="p">,</span>
                    <span class="n">layer_activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_layer_activation</span><span class="p">,</span>
                    <span class="n">output_activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_reg_activation</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">reg_layers</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">reg_layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_checkModelParams</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Function used to check the input parameters. &quot;&quot;&quot;</span>
        <span class="c1"># check number of task parameters</span>
        <span class="n">checkMultiInputTypes</span><span class="p">(</span>
            <span class="p">(</span><span class="s1">&#39;n_clf_task&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clf_task</span><span class="p">,</span> <span class="p">[</span><span class="nb">int</span><span class="p">]),</span>
            <span class="p">(</span><span class="s1">&#39;n_reg_task&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_reg_task</span><span class="p">,</span> <span class="p">[</span><span class="nb">int</span><span class="p">]))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clf_task</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s1">&#39;The number of classification tasks (&quot;n_clf_task&quot;) cannot &#39;</span>
                <span class="s1">&#39;be less than 0 (provided </span><span class="si">%d</span><span class="s1">).&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clf_task</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_reg_task</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s1">&#39;The number of regression tasks (&quot;n_reg_task&quot;) cannot &#39;</span>
                <span class="s1">&#39;be less than 0 (provided </span><span class="si">%d</span><span class="s1">).&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_reg_task</span><span class="p">)</span>
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clf_task</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_reg_task</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s1">&#39;n_clf_task + n_reg_task cannot be less than 2 (provided </span><span class="si">%d</span><span class="s1">).&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_clf_task</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_reg_task</span><span class="p">))</span>

        <span class="c1"># put activation functions into a list</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_clf_activation</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">multt_clf_activation</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_clf_activation</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clf_task</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_reg_activation</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">multt_reg_activation</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_reg_activation</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_reg_task</span>

        <span class="c1"># check activation functions shape</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_clf_activation</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clf_task</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Missmatch between activation functions (</span><span class="si">%d</span><span class="s1">) and classification tasks (</span><span class="si">%d</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_clf_activation</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clf_task</span><span class="p">))</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_reg_activation</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_reg_task</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Missmatch between activation functions (</span><span class="si">%d</span><span class="s1">) and regression tasks (</span><span class="si">%d</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_reg_activation</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_reg_task</span><span class="p">))</span>

        <span class="n">checkMultiInputTypes</span><span class="p">(</span>
            <span class="p">(</span><span class="s1">&#39;in_feats&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_feats</span><span class="p">,</span> <span class="p">[</span><span class="nb">int</span><span class="p">]),</span>
            <span class="p">(</span><span class="s1">&#39;emb_feats&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_feats</span><span class="p">,</span> <span class="p">[</span><span class="nb">int</span><span class="p">]),</span>
            <span class="p">(</span><span class="s1">&#39;layer_dims&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_dims</span><span class="p">,</span> <span class="p">[</span><span class="nb">list</span><span class="p">]),</span>
            <span class="p">(</span><span class="s1">&#39;multt_layer_dims&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">multt_layer_dims</span><span class="p">,</span> <span class="p">[</span><span class="nb">list</span><span class="p">]),</span>
            <span class="p">(</span><span class="s1">&#39;multt_dropout&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">multt_dropout</span><span class="p">,</span> <span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">)]),</span>
            <span class="p">(</span><span class="s1">&#39;multt_layer_activation&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">multt_layer_activation</span><span class="p">,</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">)]),</span>
            <span class="p">(</span><span class="s1">&#39;multt_batchnorm&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">multt_batchnorm</span><span class="p">,</span> <span class="p">[</span><span class="nb">bool</span><span class="p">]),</span>
            <span class="p">(</span><span class="s1">&#39;multt_clf_activation&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">multt_clf_activation</span><span class="p">,</span> <span class="p">[</span><span class="nb">list</span><span class="p">]),</span>
            <span class="p">(</span><span class="s1">&#39;multt_reg_activation&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">multt_reg_activation</span><span class="p">,</span> <span class="p">[</span><span class="nb">list</span><span class="p">]),</span>
            <span class="p">(</span><span class="s1">&#39;layer_dropout&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_dropout</span><span class="p">,</span> <span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">)]),</span>
            <span class="p">(</span><span class="s1">&#39;layer_activation&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_activation</span><span class="p">,</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">)]),</span>
            <span class="p">(</span><span class="s1">&#39;batchnorm&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batchnorm</span><span class="p">,</span> <span class="p">[</span><span class="nb">bool</span><span class="p">])</span>
        <span class="p">)</span>

        <span class="c1"># check number of feature parameters</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_feats</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s1">&#39;The number of input features (&quot;in_feats&quot;) cannot be less than 1 (provided </span><span class="si">%d</span><span class="s1">).&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_feats</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_feats</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s1">&#39;The number of embedding features (&quot;emb_feats&quot;) cannot be less than 1 (provided </span><span class="si">%d</span><span class="s1">).&#39;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb_feats</span><span class="p">)</span>

        <span class="c1"># check activation functions for classification tasks</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_clf_activation</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_clf_activation</span><span class="p">):</span>
                <span class="n">checkInputType</span><span class="p">(</span><span class="s1">&#39;multt_clf_activation[</span><span class="si">%d</span><span class="s1">]&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="p">[</span><span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">),</span> <span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">])</span>

        <span class="c1"># check activation functions for regression tasks</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_reg_activation</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">multt_reg_activation</span><span class="p">):</span>
                <span class="n">checkInputType</span><span class="p">(</span><span class="s1">&#39;multt_reg_activation[</span><span class="si">%d</span><span class="s1">]&#39;</span> <span class="o">%</span> <span class="n">i</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="p">[</span><span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">),</span> <span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">])</span>

<div class="viewcode-block" id="MultiTaskFFN.forward"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.MultiTaskFFN.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">**</span><span class="n">_</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>

        <span class="c1"># forward pass for the feature extractor</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># forward pass for the classification tasks</span>
        <span class="n">clf_out</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">clf_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">emb</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">clf_layers</span><span class="p">))]</span>
        <span class="c1"># forward pass for the regression tasks</span>
        <span class="n">reg_out</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_layers</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">emb</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reg_layers</span><span class="p">))]</span>

        <span class="c1"># concat classification and regression predictions</span>
        <span class="n">comb_preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">clf_out</span> <span class="o">+</span> <span class="n">reg_out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">comb_preds</span></div></div>


<div class="viewcode-block" id="MultiTaskFFNv2"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.MultiTaskFFNv2">[docs]</a><span class="k">class</span> <span class="nc">MultiTaskFFNv2</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; (Simplified version of :class:`gojo.deepl.models.MultiTaskFFN`) Model adapted to perform multi-task</span>
<span class="sd">    classification with a layer specialized in extracting features (accessible through :meth:`feature_extractor`) and,</span>
<span class="sd">    as is typical in multi-task model training, layers specialized in performing the different tasks (accessible</span>
<span class="sd">    through :meth:`multitask_projection`). The model will return a tensor with the outputs of each of the layers from</span>
<span class="sd">    the input parameter `multitask_projection` concatenated in the same order as declared in the input parameter.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">     feature_extractor : torch.nn.Module</span>
<span class="sd">        Layer that will take the input from the model and generate an embedded representation that will be subsequently</span>
<span class="sd">        used by the layers defined in `multitask_projection`.</span>

<span class="sd">     multitask_projection : torch.nn.ModuleList</span>
<span class="sd">        Layers specialized in different tasks. Their outputs will be concatenated along dimension 1.</span>


<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import torch</span>
<span class="sd">    &gt;&gt;&gt; from gojo import deepl</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; X = torch.rand(10, 40)    # (batch_size, n_feats)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; multitask_model = deepl.models.MultiTaskFFNv2(</span>
<span class="sd">    &gt;&gt;&gt;     feature_extractor=torch.nn.Sequential(</span>
<span class="sd">    &gt;&gt;&gt;         torch.nn.Linear(40, 20),</span>
<span class="sd">    &gt;&gt;&gt;         torch.nn.ReLU()</span>
<span class="sd">    &gt;&gt;&gt;     ),</span>
<span class="sd">    &gt;&gt;&gt;     multitask_projection=torch.nn.ModuleList([</span>
<span class="sd">    &gt;&gt;&gt;         torch.nn.Sequential(</span>
<span class="sd">    &gt;&gt;&gt;             torch.nn.Linear(20, 2),</span>
<span class="sd">    &gt;&gt;&gt;             torch.nn.Tanh()</span>
<span class="sd">    &gt;&gt;&gt;         ),</span>
<span class="sd">    &gt;&gt;&gt;         torch.nn.Sequential(</span>
<span class="sd">    &gt;&gt;&gt;             torch.nn.Linear(20, 1),</span>
<span class="sd">    &gt;&gt;&gt;             torch.nn.Sigmoid()</span>
<span class="sd">    &gt;&gt;&gt;         ),</span>
<span class="sd">    &gt;&gt;&gt;     ])</span>
<span class="sd">    &gt;&gt;&gt; )</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; with torch.no_grad():</span>
<span class="sd">    &gt;&gt;&gt;     mtt_out = multitask_model(X)</span>
<span class="sd">    &gt;&gt;&gt;     emb = multitask_model.feature_extractor(X)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; mtt_out[:, :2].min(), mtt_out[:, :2].max()</span>
<span class="sd">        Out[0]: (tensor(-0.2965), tensor(0.1321))</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; mtt_out[:, 2].min(), mtt_out[:, 2].max()</span>
<span class="sd">        Out[1]: (tensor(0.3898), tensor(0.4343))</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; emb.shape</span>
<span class="sd">        Out[2]: torch.Size([10, 20])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">feature_extractor</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
            <span class="n">multitask_projection</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MultiTaskFFNv2</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span> <span class="o">=</span> <span class="n">feature_extractor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">multitask_projection</span> <span class="o">=</span> <span class="n">multitask_projection</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">_checkModelParams</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_checkModelParams</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Function used to check the input parameters. &quot;&quot;&quot;</span>
        <span class="n">checkMultiInputTypes</span><span class="p">(</span>
            <span class="p">(</span><span class="s1">&#39;feature_extractor&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span><span class="p">,</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]),</span>
            <span class="p">(</span><span class="s1">&#39;multitask_projection&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">multitask_projection</span><span class="p">,</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">]))</span>

<div class="viewcode-block" id="MultiTaskFFNv2.forward"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.MultiTaskFFNv2.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">**</span><span class="n">_</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>

        <span class="c1"># forward pass for the feature extractor</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># forward pass for the multitask FFNs</span>
        <span class="n">mtt_out</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="p">(</span><span class="n">emb</span><span class="p">)</span> <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">multitask_projection</span><span class="p">]</span>

        <span class="c1"># concatenate the output across the batch dimension</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">mtt_out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span></div></div>


<div class="viewcode-block" id="GNN"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.GNN">[docs]</a><span class="k">class</span> <span class="nc">GNN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Graph Neural Network wrapper for graph classification. This model allows integrating data in the form of a</span>
<span class="sd">    graph through a model defined `gnn_model` parameter, and  tabular data through a model defined in `ffn_model` and</span>
<span class="sd">    the resulting information will be fused using the defined `fusion_model`.</span>

<span class="sd">    If the parameter `ffn_model` is not provided only the embeddings generated by the model defined in `gnn_model`</span>
<span class="sd">    will be passed to the fusion layer (`fusion_model`). If the fusion_model parameter is not given, the embeddings</span>
<span class="sd">    resulting from the `gnn_model` model will be returned directly or, if the `ffn_model` parameter is given, the</span>
<span class="sd">    embeddings generated by both models concatenated.</span>


<span class="sd">    Parameters</span>
<span class="sd">    -----------</span>
<span class="sd">    gnn_model : torch.nn.Module</span>
<span class="sd">        Graph neural network model. See `torch_geometric` for model implementations.</span>

<span class="sd">    ffn_model : torch.nn.Module, default=None</span>
<span class="sd">        Feed forward network model for generate the output.</span>

<span class="sd">    fusion_model : torch.nn.Module, default=None</span>
<span class="sd">        Fusion layer for merge GNN and FFN derived information.</span>

<span class="sd">    gp_agg : str, default=&#39;sum&#39;</span>
<span class="sd">        Graph-pooling aggregation.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">gnn_model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
            <span class="n">ffn_model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">fusion_model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">use_tabular_x</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
            <span class="n">gp_agg</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;sum&#39;</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">gnn_model</span> <span class="o">=</span> <span class="n">gnn_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ffn_model</span> <span class="o">=</span> <span class="n">ffn_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fusion_model</span> <span class="o">=</span> <span class="n">fusion_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gp_agg</span> <span class="o">=</span> <span class="n">gp_agg</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_tabular_x</span> <span class="o">=</span> <span class="n">use_tabular_x</span>

<div class="viewcode-block" id="GNN.gnnForward"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.GNN.gnnForward">[docs]</a>    <span class="k">def</span> <span class="nf">gnnForward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">gnn_model</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">edge_index</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">edge_index</span><span class="p">)</span></div>

<div class="viewcode-block" id="GNN.graphPooling"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.GNN.graphPooling">[docs]</a>    <span class="k">def</span> <span class="nf">graphPooling</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">geom</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">reduce</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">gp_agg</span><span class="p">)</span></div>

<div class="viewcode-block" id="GNN.ffnModel"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.GNN.ffnModel">[docs]</a>    <span class="k">def</span> <span class="nf">ffnModel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>

<div class="viewcode-block" id="GNN.fusionModel"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.GNN.fusionModel">[docs]</a>    <span class="k">def</span> <span class="nf">fusionModel</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>

<div class="viewcode-block" id="GNN.forward"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.GNN.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="o">**</span><span class="n">_</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        batch : torch_geometric.data.Batch</span>
<span class="sd">            `torch_geometric` batch dadta.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># GNN forward pass</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gnnForward</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

        <span class="c1"># graph-level aggregation</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">graphPooling</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">batch</span><span class="p">)</span>

        <span class="c1"># FFN forward pass for the tabular information</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ffn_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffnModel</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">tabular_x</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="s1">&#39;tabular_x&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ffn_out</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">tabular_x</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">ffn_out</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># concatenate FFN/tabular information with the graph embeddings</span>
        <span class="k">if</span> <span class="n">ffn_out</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">out</span><span class="p">,</span> <span class="n">ffn_out</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># FFN forward pass for the fusion model</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion_model</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusionModel</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span></div></div>


<div class="viewcode-block" id="VanillaVAE"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.VanillaVAE">[docs]</a><span class="k">class</span> <span class="nc">VanillaVAE</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Basic variational autoencoder model as presented in (https://arxiv.org/abs/1312.6114).</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    encoder : torch.nn.Module</span>
<span class="sd">        Encoder model. The encoder will model P(Z|X) during training.</span>

<span class="sd">    encoder_out_dim : int</span>
<span class="sd">        Output shape of the encoder.</span>

<span class="sd">    decoder : torch.nn.Module</span>
<span class="sd">        Decoder model. The decoder will model P(X|Z) where P(Z) is assumed to follow a multivariate Gaussian</span>
<span class="sd">        distribution.</span>

<span class="sd">    decoder_in_dim : int</span>
<span class="sd">        Expected input shape for the decoder.</span>

<span class="sd">    latent_dim : int</span>
<span class="sd">        Latent dimensions of Z.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">encoder</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
            <span class="n">encoder_out_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">decoder</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
            <span class="n">decoder_in_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">latent_dim</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VanillaVAE</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">checkMultiInputTypes</span><span class="p">(</span>
            <span class="p">(</span><span class="s1">&#39;encoder&#39;</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]),</span>
            <span class="p">(</span><span class="s1">&#39;decoder&#39;</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]),</span>
            <span class="p">(</span><span class="s1">&#39;latent_dim&#39;</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="p">[</span><span class="nb">int</span><span class="p">]))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span> <span class="o">=</span> <span class="n">latent_dim</span>

        <span class="c1"># create the projection layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ffn_mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoder_out_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ffn_var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoder_out_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ffn_latent_to_decoder</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span> <span class="n">decoder_in_dim</span><span class="p">)</span>

<div class="viewcode-block" id="VanillaVAE.encode"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.VanillaVAE.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot; Generate the latent representation</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : torch.Tensor</span>
<span class="sd">            Input data</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        mu_std : Tuple[torch.Tensor, torch.Tensor]</span>
<span class="sd">            Mean and standard deviation of the latent dimensions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">enc_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn_mu</span><span class="p">(</span><span class="n">enc_out</span><span class="p">)</span>
        <span class="n">std</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn_var</span><span class="p">(</span><span class="n">enc_out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">mu</span><span class="p">,</span> <span class="n">std</span></div>

<div class="viewcode-block" id="VanillaVAE.decode"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.VanillaVAE.decode">[docs]</a>    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">Z</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Decode the latent representation</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        Z : torch.Tensor</span>
<span class="sd">            Latent representation generated by the :meth`reparametrize` function.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        decoder_out : torch.Tensor</span>
<span class="sd">            Decoder output.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">z_projection</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn_latent_to_decoder</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z_projection</span><span class="p">)</span></div>

<div class="viewcode-block" id="VanillaVAE.reparametrize"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.VanillaVAE.reparametrize">[docs]</a>    <span class="k">def</span> <span class="nf">reparametrize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">logvar</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Reparametrization trick as described in &quot;Auto-Encoding Variational Bayes&quot; from Kigma and Welling.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        mu : torch.Tensor</span>
<span class="sd">            Mean of the distribution of the latent variables.</span>

<span class="sd">        logvar : torch.Tensor</span>
<span class="sd">            Logarithm of the standard deviation of the latent variables.</span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        sample : torch.Tensor</span>
<span class="sd">            Sample from the latent variable distribution.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">eps</span> <span class="o">*</span> <span class="n">std</span> <span class="o">+</span> <span class="n">mu</span></div>

<div class="viewcode-block" id="VanillaVAE.forward"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.VanillaVAE.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">dict</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot; Forward function. This function will do the following operations:</span>

<span class="sd">            X -&gt; encoder -&gt; projection -&gt; [mu, std] -&gt; reparametrization -&gt; decoder</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : torch.Tensor</span>
<span class="sd">            Input data to be codified.</span>


<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        output : Tuple[torch.Tensor, dict]</span>
<span class="sd">            This function will return a two element tuple where the first element will correspond to the reconstructed</span>
<span class="sd">            input and the second element to a dictionary with the mean and logvar vectors of the latent representations</span>
<span class="sd">            generated by the encoder.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparametrize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">x_hat</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x_hat</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;mu&#39;</span><span class="p">:</span> <span class="n">mu</span><span class="p">,</span> <span class="s1">&#39;logvar&#39;</span><span class="p">:</span> <span class="n">logvar</span><span class="p">}</span></div>

<div class="viewcode-block" id="VanillaVAE.sample"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.VanillaVAE.sample">[docs]</a>    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">current_device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Sample from the latent space.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_samples : int</span>
<span class="sd">            Number of samples</span>

<span class="sd">        current_device : str, default=&#39;cpu&#39;</span>
<span class="sd">            Device to run the model</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        samples : torch.Tensor</span>
<span class="sd">            Tensor of shape (n_samples, *)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">latent_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">current_device</span><span class="p">)</span>
            <span class="n">samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">samples</span></div></div>


<div class="viewcode-block" id="FusionModel"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.FusionModel">[docs]</a><span class="k">class</span> <span class="nc">FusionModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Model designed to allow the merging of information from several models that receive different input values.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    encoders : torch.nn.ModuleList</span>
<span class="sd">        Models associated with each of the inputs. The models will be executed in order by receiving as argument the </span>
<span class="sd">        input parameters of the model after eliminating the entries defined in the indexes of parameter `ignore_inputs`. </span>

<span class="sd">    fusion_model : torch.nn.Module</span>
<span class="sd">        Fusion model that will receive all the merged data internally (either by the function defined in `concat_fn` or </span>
<span class="sd">        concatenated along dimension 1 by default) and will generate the final model output.</span>

<span class="sd">    concat_fn : callable, default=None</span>
<span class="sd">        Function used to concatenate the outpus of the input models. This function will receive as input a list of </span>
<span class="sd">        tensors and must return a unified tensor. By default, function `torch.cat` will be called by concatenating the </span>
<span class="sd">        outputs along dimension 1.</span>

<span class="sd">    ignore_inputs : list, default=None</span>
<span class="sd">        List specifying the input items to be ignored. </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> 
            <span class="n">encoders</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">,</span>
            <span class="n">fusion_model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
            <span class="n">concat_fn</span><span class="p">:</span> <span class="n">callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">ignore_inputs</span><span class="p">:</span> <span class="nb">list</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FusionModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoders</span> <span class="o">=</span> <span class="n">encoders</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fusion_model</span> <span class="o">=</span> <span class="n">fusion_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">concat_fn</span> <span class="o">=</span> <span class="n">concat_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ignore_inputs</span> <span class="o">=</span> <span class="n">ignore_inputs</span> <span class="k">if</span> <span class="n">ignore_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_checkModelParams</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">_checkModelParams</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Function used to check the input parameters. &quot;&quot;&quot;</span>
        <span class="n">checkMultiInputTypes</span><span class="p">(</span>
            <span class="p">(</span><span class="s1">&#39;encoders&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoders</span><span class="p">,</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">]),</span>
            <span class="p">(</span><span class="s1">&#39;fusion_model&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion_model</span><span class="p">,</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]),</span>
            <span class="p">(</span><span class="s1">&#39;ignore_inputs&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_inputs</span><span class="p">,</span> <span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="kc">None</span><span class="p">)]))</span>

<div class="viewcode-block" id="FusionModel.encode"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.FusionModel.encode">[docs]</a>    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot; Processes the input elements through the models defined in parameter `encoders` and returns a unified </span>
<span class="sd">        vector as specified by argument `concat_fn`. &quot;&quot;&quot;</span>

        <span class="c1"># get the model device </span>
        <span class="n">devices</span> <span class="o">=</span> <span class="p">{</span><span class="n">param</span><span class="o">.</span><span class="n">device</span> <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">()}</span>

        <span class="c1"># convert the input tensors to the same device</span>
        <span class="n">device</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">devices</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">device</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">devices</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Models have been detected in different devices, in the current implementation all&#39;</span>
                            <span class="s1">&#39; models must be in the same device.&#39;</span><span class="p">)</span>

        <span class="c1"># check input sizes</span>
        <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ignore_inputs</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoders</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s1">&#39;Inconsistent number of inputs (</span><span class="si">%d</span><span class="s1">) and models (</span><span class="si">%d</span><span class="s1">) considering that </span><span class="si">%d</span><span class="s1"> entries will be ignored.&#39;</span> <span class="o">%</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoders</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ignore_inputs</span><span class="p">)))</span>

        <span class="c1"># select inputs </span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ignore_inputs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">input_</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">input_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_inputs</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="c1"># check remaining input sizes</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoders</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s1">&#39;Missmatch in input size (inputs </span><span class="si">%d</span><span class="s1">, models </span><span class="si">%d</span><span class="s1">) after ignoring inputs </span><span class="si">%r</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoders</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">ignore_inputs</span><span class="p">))</span>

        <span class="c1"># perform the forward pass of the input models</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">encoders</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoders</span><span class="p">))]</span>

        <span class="c1"># apply the concatenation function if provided</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">checkCallable</span><span class="p">(</span><span class="s1">&#39;concat_fn&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat_fn</span><span class="p">)</span>
            <span class="n">fused_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">concat_fn</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">fused_output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">fused_output</span></div>


<div class="viewcode-block" id="FusionModel.forward"><a class="viewcode-back" href="../../../gojo.deepl.html#gojo.deepl.models.FusionModel.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">inputs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>

        <span class="c1"># perform the forward pass of the individual models and concatenate the output</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="o">*</span><span class="n">inputs</span><span class="p">)</span>

        <span class="c1"># fuse the output models information</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fusion_model</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">out</span></div></div>


</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Fernando García Gutiérrez.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>