<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Model evaluation by cross validation &mdash; gojo - Documentation 0.1.0 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="gojo.core package" href="../gojo.core.html" />
    <link rel="prev" title="GoJo - Make Machine/Deep Learning pipelines simple" href="../index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #F24C4C" >
            <a href="../index.html" class="icon icon-home"> gojo - Documentation
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Hands-on</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#"><strong>Model evaluation by cross validation</strong></a><ul>
<li class="toctree-l2"><a class="reference internal" href="#definition-and-evaluation-of-a-support-vector-machine-svm-model"><strong>Definition and evaluation of a Support Vector Machine (SVM) model</strong></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#understanding-svms-with-polynomial-kernels"><strong>Understanding SVMs with Polynomial Kernels</strong></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#introduction-to-svm"><strong>Introduction to SVM</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-mathematical-foundation-hyperplane"><strong>The Mathematical Foundation - Hyperplane</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-mathematical-foundation-maximizing-the-margin"><strong>The Mathematical Foundation - Maximizing the Margin</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-mathematical-foundation-the-optimization-problem"><strong>The Mathematical Foundation - The Optimization Problem</strong></a></li>
<li class="toctree-l4"><a class="reference internal" href="#the-mathematical-foundation-introducing-kernels"><strong>The Mathematical Foundation - Introducing Kernels</strong></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hands-on"><strong>Hands-on</strong></a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../gojo.core.html">gojo.core package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gojo.core.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.core.html#module-gojo.core.evaluation">gojo.core.evaluation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.core.html#module-gojo.core.loops">gojo.core.loops module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.core.html#module-gojo.core.report">gojo.core.report module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.core.html#module-gojo.core">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gojo.interfaces.html">gojo.interfaces package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gojo.interfaces.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.interfaces.html#module-gojo.interfaces.model">gojo.interfaces.model module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.interfaces.html#module-gojo.interfaces.data">gojo.interfaces.data module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.interfaces.html#module-gojo.interfaces.transform">gojo.interfaces.transform module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.interfaces.html#module-gojo.interfaces">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gojo.deepl.html">gojo.deepl package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gojo.deepl.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.deepl.html#module-gojo.deepl.callback">gojo.deepl.callback module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.deepl.html#module-gojo.deepl.cnn">gojo.deepl.cnn module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.deepl.html#module-gojo.deepl.ffn">gojo.deepl.ffn module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.deepl.html#module-gojo.deepl.loading">gojo.deepl.loading module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.deepl.html#module-gojo.deepl.loops">gojo.deepl.loops module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.deepl.html#module-gojo.deepl.loss">gojo.deepl.loss module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.deepl.html#module-gojo.deepl.models">gojo.deepl.models module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.deepl.html#module-gojo.deepl">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gojo.plotting.html">gojo.plotting package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gojo.plotting.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.plotting.html#module-gojo.plotting.basic">gojo.plotting.basic module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.plotting.html#module-gojo.plotting.classification">gojo.plotting.classification module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.plotting.html#module-gojo.plotting">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gojo.util.html">gojo.util package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gojo.util.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.util.html#module-gojo.util.io">gojo.util.io module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.util.html#module-gojo.util.login">gojo.util.login module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.util.html#module-gojo.util.splitter">gojo.util.splitter module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.util.html#module-gojo.util.tools">gojo.util.tools module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.util.html#module-gojo.util.validation">gojo.util.validation module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../gojo.util.html#module-gojo.util">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gojo.experimental.html">gojo.experimental package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../gojo.experimental.html#module-gojo.experimental">Module contents</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #F24C4C" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">gojo - Documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li><strong>Model evaluation by cross validation</strong></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/examples/Example_1_Model_evaluation_by_cross_validation.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul><div class="rst-breadcrumbs-buttons" role="navigation" aria-label="Sequential page navigation">
        <a href="../index.html" class="btn btn-neutral float-left" title="GoJo - Make Machine/Deep Learning pipelines simple" accesskey="p"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../gojo.core.html" class="btn btn-neutral float-right" title="gojo.core package" accesskey="n">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
  </div>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="model-evaluation-by-cross-validation">
<h1><strong>Model evaluation by cross validation</strong><a class="headerlink" href="#model-evaluation-by-cross-validation" title="Permalink to this headline"></a></h1>
<p>This example shows a basic use case when developing Machine Learning
models, the estimation of the generalization capacity of the model. This
example uses the toy Wine dataset to perform the tests. It is a super
simple dataset but for purposes of showing the basic operation of the
module it serves its purpose.</p>
<p><strong>Why cross-validation?</strong></p>
<p>Cross-validation is crucial in evaluating machine learning models
because it provides a more reliable estimate of the model’s performance.
Here’s a brief explanation:</p>
<ol class="arabic simple">
<li><p>Robust Performance Evaluation: Cross-validation involves splitting
the dataset into multiple subsets and training the model multiple
times, each time using a different subset as the validation set. This
ensures that the model is tested on various data points, leading to a
more accurate assessment of its generalization ability.</p></li>
<li><p>Reduced Overfitting: By evaluating the model on different splits of
the data, cross-validation helps detect overfitting. A model that
performs well on one particular split but poorly on others is likely
overfitting to the training data.</p></li>
<li><p>Better Use of Data: Cross-validation makes efficient use of the
available data, especially in cases where the dataset is limited. By
rotating the training and validation sets, it ensures that every data
point is used for both training and validation, providing a
comprehensive evaluation.</p></li>
<li><p>Model Selection: It aids in model selection and hyperparameter
tuning. By comparing performance across different models or
hyperparameter settings using cross-validation, one can choose the
best-performing model or configuration with greater confidence.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>

<span class="c1"># for a simpler use, we load the different submodules of the library</span>
<span class="c1">#     - the gojo.core module contains all the subroutines used to evaluate the models</span>
<span class="c1">#     - the gojo.interfaces module provides a standardized way to interact with the different elements of gojo.core</span>
<span class="c1">#     - the gojo.util module implements some utilities</span>
<span class="kn">from</span> <span class="nn">gojo</span> <span class="kn">import</span> <span class="n">core</span>
<span class="kn">from</span> <span class="nn">gojo</span> <span class="kn">import</span> <span class="n">interfaces</span>
<span class="kn">from</span> <span class="nn">gojo</span> <span class="kn">import</span> <span class="n">util</span>
</pre></div>
</div>
<pre class="literal-block">C:Usersfgarciaanaconda3envsmlv0libsite-packagestqdmauto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm</pre>
<p>The Wine dataset is a classic dataset used in machine learning for
classification tasks. It contains data on various chemical properties of
wines derived from three different cultivars of grapes. Here is a brief
description of the typical Wine dataset:</p>
<p><strong>Purpose</strong>: The Wine dataset is primarily used for classification
tasks, where the goal is to predict the class of wine (cultivar) based
on its chemical properties.</p>
<p><strong>Features</strong>: The dataset includes 13 continuous features, which are:</p>
<ul class="simple">
<li><p>Alcohol</p></li>
<li><p>Malic acid</p></li>
<li><p>Ash</p></li>
<li><p>Alcalinity of ash</p></li>
<li><p>Magnesium</p></li>
<li><p>Total phenols</p></li>
<li><p>Flavanoids</p></li>
<li><p>Nonflavanoid phenols</p></li>
<li><p>Proanthocyanins</p></li>
<li><p>Color intensity</p></li>
<li><p>Hue</p></li>
<li><p>OD280/OD315 of diluted wines</p></li>
<li><p>Proline</p></li>
</ul>
<p><strong>Target Variable</strong>: The target variable is the class label, which
indicates the cultivar of the wine. There are three classes:</p>
<ul class="simple">
<li><p>Class 1</p></li>
<li><p>Class 2</p></li>
<li><p>Class 3</p></li>
</ul>
<p><strong>Sample Size</strong>: The dataset consists of 178 instances.</p>
<p><strong>Source</strong>: The dataset was created by M. Forina, et al. and is often
referenced in the UCI Machine Learning Repository.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># load test dataset (Wine)</span>
<span class="n">wine_dt</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_wine</span><span class="p">()</span>

<span class="c1"># create the target variable. Classification problem 0 vs rest</span>
<span class="c1"># to see the target names you can use wine_dt[&#39;target_names&#39;]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">wine_dt</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">wine_dt</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>

<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">((</span><span class="mi">178</span><span class="p">,</span> <span class="mi">13</span><span class="p">),</span> <span class="p">(</span><span class="mi">178</span><span class="p">,))</span>
</pre></div>
</div>
<section id="definition-and-evaluation-of-a-support-vector-machine-svm-model">
<h2><strong>Definition and evaluation of a Support Vector Machine (SVM) model</strong><a class="headerlink" href="#definition-and-evaluation-of-a-support-vector-machine-svm-model" title="Permalink to this headline"></a></h2>
<p>In this case we will go naive to define a model based on support vector
machines (SVM) using a polynomial kernel in a straightforward way
(without any data processing).</p>
<section id="understanding-svms-with-polynomial-kernels">
<h3><strong>Understanding SVMs with Polynomial Kernels</strong><a class="headerlink" href="#understanding-svms-with-polynomial-kernels" title="Permalink to this headline"></a></h3>
<blockquote>
<div><p><strong>This introduction to SVMs can be skipped</strong></p>
</div></blockquote>
<section id="introduction-to-svm">
<h4><strong>Introduction to SVM</strong><a class="headerlink" href="#introduction-to-svm" title="Permalink to this headline"></a></h4>
<p>Support Vector Machines are a powerful set of supervised learning
algorithms used for classification and regression tasks. The core idea
behind SVMs is to find a hyperplane that best separates the data points
of different classes in a high-dimensional space.</p>
</section>
<section id="the-mathematical-foundation-hyperplane">
<h4><strong>The Mathematical Foundation - Hyperplane</strong><a class="headerlink" href="#the-mathematical-foundation-hyperplane" title="Permalink to this headline"></a></h4>
<p>In a binary classification problem, an SVM aims to find the optimal
hyperplane that separates the data points into two classes. A hyperplane
in an (n)-dimensional space is defined by the equation:</p>
<div class="math notranslate nohighlight">
\[\mathbf{w} \cdot \mathbf{x} + b = 0\]</div>
<p>where: - <span class="math notranslate nohighlight">\(\mathbf{w}\)</span> is the weight vector perpendicular to the
hyperplane. - <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is the feature vector. - <span class="math notranslate nohighlight">\(b\)</span> is
the bias term.</p>
</section>
<section id="the-mathematical-foundation-maximizing-the-margin">
<h4><strong>The Mathematical Foundation - Maximizing the Margin</strong><a class="headerlink" href="#the-mathematical-foundation-maximizing-the-margin" title="Permalink to this headline"></a></h4>
<p>The objective of an SVM is to maximize the margin, which is the distance
between the hyperplane and the nearest data points from each class.
These nearest points are called support vectors. The margin <span class="math notranslate nohighlight">\(M\)</span> is
given by:</p>
<div class="math notranslate nohighlight">
\[M = \frac{2}{\|\mathbf{w}\|}\]</div>
<p>Maximizing the margin is equivalent to minimizing $
|:raw-latex:<cite>mathbf{w}</cite>|^2 $, subject to the constraint that all data
points are correctly classified:</p>
<div class="math notranslate nohighlight">
\[y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1\]</div>
<p>for all <span class="math notranslate nohighlight">\(i\)</span>, where $ y_i $ is the class label of $
<a href="#id1"><span class="problematic" id="id2">:raw-latex:`\mathbf{x}`</span></a>_i $.</p>
</section>
<section id="the-mathematical-foundation-the-optimization-problem">
<h4><strong>The Mathematical Foundation - The Optimization Problem</strong><a class="headerlink" href="#the-mathematical-foundation-the-optimization-problem" title="Permalink to this headline"></a></h4>
<p>This leads to the following optimization problem:</p>
<p>Minimize:</p>
<div class="math notranslate nohighlight">
\[\frac{1}{2} \|\mathbf{w}\|^2\]</div>
<p>Subject to:</p>
<div class="math notranslate nohighlight">
\[y_i (\mathbf{w} \cdot \mathbf{x}_i + b) \geq 1\]</div>
</section>
<section id="the-mathematical-foundation-introducing-kernels">
<h4><strong>The Mathematical Foundation - Introducing Kernels</strong><a class="headerlink" href="#the-mathematical-foundation-introducing-kernels" title="Permalink to this headline"></a></h4>
<p>In many cases, the data is not linearly separable in the original
feature space. SVMs address this by using kernel functions to map the
data into a higher-dimensional space where it becomes linearly
separable. One common kernel is the polynomial kernel.</p>
<ul class="simple">
<li><p>Polynomial Kernel</p></li>
</ul>
<p>The polynomial kernel allows the SVM to fit non-linear decision
boundaries. It is defined as:</p>
<div class="math notranslate nohighlight">
\[K(\mathbf{x}_i, \mathbf{x}_j) = (\mathbf{x}_i \cdot \mathbf{x}_j + c)^d\]</div>
<p>where: - <span class="math notranslate nohighlight">\((\mathbf{x}_i \cdot \mathbf{x}_j)\)</span> is the dot product of
the input vectors. - $ c $ is a constant that trades off the influence
of higher-order versus lower-order terms. - $ d $ is the degree of the
polynomial.</p>
<ul class="simple">
<li><p>How It Works</p></li>
</ul>
<ol class="arabic simple">
<li><p><strong>Mapping to Higher Dimensions</strong>: The polynomial kernel maps the
input features into a higher-dimensional space without explicitly
computing the coordinates in that space. This is computationally
efficient and allows the SVM to find complex decision boundaries.</p></li>
<li><p><strong>Dual Formulation</strong>: The SVM problem can be solved in its dual form,
where the optimization problem depends on the dot products of the
input vectors. The polynomial kernel replaces these dot products,
effectively transforming the problem into a higher-dimensional space.</p></li>
</ol>
<ul class="simple">
<li><p>The Dual Optimization Problem</p></li>
</ul>
<p>Using the polynomial kernel, the dual form of the optimization problem
becomes:</p>
<p>Maximize:</p>
<div class="math notranslate nohighlight">
\[\sum_{i=1}^{n} \alpha_i - \frac{1}{2} \sum_{i=1}^{n} \sum_{j=1}^{n} \alpha_i \alpha_j y_i y_j K(\mathbf{x}_i, \mathbf{x}_j)\]</div>
<p>Subject to:</p>
<div class="math notranslate nohighlight">
\[\sum_{i=1}^{n} \alpha_i y_i = 0\]</div>
<div class="math notranslate nohighlight">
\[0 \leq \alpha_i \leq C\]</div>
<p>where ( <a href="#id3"><span class="problematic" id="id4">:raw-latex:`\alpha`</span></a>_i ) are the Lagrange multipliers and (C) is
a regularization parameter that controls the trade-off between
maximizing the margin and minimizing the classification error.</p>
<p>Support Vector Machines with polynomial kernels are a powerful tool for
classification tasks, especially when dealing with non-linear data. By
transforming the input space into a higher-dimensional feature space,
SVMs can find complex decision boundaries that separate the classes
effectively. The polynomial kernel is particularly useful for capturing
interactions between features up to a certain degree, making SVMs a
versatile choice for many machine learning problems.</p>
</section>
</section>
<section id="hands-on">
<h3><strong>Hands-on</strong><a class="headerlink" href="#hands-on" title="Permalink to this headline"></a></h3>
<p>In order for the sklearn SVM model to be used in gojo we can use the
<strong>SklearnModelWrapper</strong> interface.</p>
<p>This class simply needs to be provided with the class of a sklearn model
(or any other class that is a subclass of
<strong>sklearn.base.BaseEstimator</strong>), and then optional parameters used to
initialize instances of the class provided in <em>model_class</em>.</p>
<blockquote>
<div><p>for more information use <strong>help(interfaces.SklearnModelWrapper)</strong></p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">interfaces</span><span class="o">.</span><span class="n">SklearnModelWrapper</span><span class="p">(</span>
    <span class="n">model_class</span><span class="o">=</span><span class="n">SVC</span><span class="p">,</span>
    <span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="n">degree</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">coef0</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
    <span class="n">cache_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span>
<span class="n">model</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">SklearnModelWrapper</span><span class="p">(</span>
    <span class="n">base_model</span><span class="o">=</span><span class="s1">&#39;sklearn.svm._classes.SVC&#39;</span><span class="p">,</span>
    <span class="n">model_params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;coef0&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;cache_size&#39;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span> <span class="s1">&#39;class_weight&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">},</span>
    <span class="n">predict_proba</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">supress_warnings</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># to access a dictionary with the parameters provided to the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">getParameters</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span>
 <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
 <span class="s1">&#39;coef0&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
 <span class="s1">&#39;cache_size&#39;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span>
 <span class="s1">&#39;class_weight&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">}</span>
</pre></div>
</div>
<p>Let’s try some inference without having trained the model yet.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">performInference</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">ex</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">ex</span><span class="p">),</span> <span class="n">ex</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;gojo.exception.UnfittedEstimator&#39;&gt; Before making inferences through a model by calling the &quot;performInferences()&quot; method, it is necessary to adjust the model by calling the &quot;train()&quot; method.
</pre></div>
</div>
<p>In this case we get an exception indicating that before making
inferences the model must be adjusted. To do this let’s call the method
train</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">performInference</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y_hat</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
       <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
       <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
       <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
       <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
       <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
       <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
       <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span>
       <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<p>Now let’s make a quick calculation of the model’s accuracy</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: </span><span class="si">{:.2f}</span><span class="s1">%&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">((</span><span class="n">y_hat</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Accuracy</span><span class="p">:</span> <span class="mf">76.40</span><span class="o">%</span>
</pre></div>
</div>
<p>If we want to reset the internal state of the model to forget previous
settings we can use the <strong>resetFit</strong> method</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">is_fitted</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kc">True</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">resetFit</span><span class="p">()</span>  <span class="c1"># reset previous model fits</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">is_fitted</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kc">False</span>
</pre></div>
</div>
<p>We see that using a point-blank model without training and testing it on
the same data we can expect an accuracy of 76.40%. Let us now try to
evaluate it by cross-validation. For this we can use the function
<strong>core.evalCrossVal</strong></p>
<blockquote>
<div><p>for more information use <strong>help(core.evalCrossVal)</strong></p>
</div></blockquote>
<p>To evaluate the model we will load a cross validation object using the
gojo utilities module, for example a 5-fold cross validation sklearn
object with class stratification.</p>
<blockquote>
<div><p>for more information use <strong>help(util.splitter.getCrossValObj)</strong></p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cv_obj</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">splitter</span><span class="o">.</span><span class="n">getCrossValObj</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">repeats</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stratified</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">cv_obj</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">RepeatedStratifiedKFold</span><span class="p">(</span><span class="n">n_repeats</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
<p>With the data, the model and a way to evaluate the model, a cross
validation can now be performed. The result of calling this function
will be an object of type <strong>gojo.core.CVReport</strong>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cv_report</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">evalCrossVal</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="n">cv_obj</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">cv_report</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Performing</span> <span class="n">cross</span><span class="o">-</span><span class="n">validation</span><span class="o">...</span><span class="p">:</span> <span class="mi">5</span><span class="n">it</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">987.96</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">gojo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">CVReport</span> <span class="n">at</span> <span class="mh">0x26c7351b640</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>The class <strong>gojo.core.CVReport</strong> implements some interesting
functionalities, let’s see some of them directly using the code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cv_report</span><span class="o">.</span><span class="n">getTestPredictions</span><span class="p">()</span>  <span class="c1"># access to all the predictions made on the test</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>pred_labels</th>
      <th>true_labels</th>
    </tr>
    <tr>
      <th>n_fold</th>
      <th>indices</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="5" valign="top">0</th>
      <th>9</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>13</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>20</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>21</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">4</th>
      <th>153</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>158</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>159</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>170</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>172</th>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>178 rows × 2 columns</p>
</div><p>By passing it a list of metrics (for example those already defined in
gojo.core.evaluation) we can directly obtain an evaluation of the model.</p>
<p>Note that this list of metrics are instances of the
<strong>gojo.core.Metrics</strong> class.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_performance</span> <span class="o">=</span> <span class="n">cv_report</span><span class="o">.</span><span class="n">getScores</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">getDefaultMetrics</span><span class="p">(</span><span class="s1">&#39;binary_classification&#39;</span><span class="p">),</span> <span class="n">supress_warnings</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model_performance</span>
</pre></div>
</div>
<pre class="literal-block">{'test':    accuracy  balanced_accuracy  precision    recall  sensitivity  specificity   0  0.694444           0.685065   0.600000  0.642857     0.642857     0.727273
 1  0.750000           0.730519   0.692308  0.642857     0.642857     0.818182
 2  0.805556           0.804762   0.750000  0.800000     0.800000     0.809524
 3  0.828571           0.833333   0.750000  0.857143     0.857143     0.809524
 4  0.742857           0.738095   0.666667  0.714286     0.714286     0.761905

    negative_predictive_value  f1_score       auc  n_fold
 0                   0.761905  0.620690  0.685065       0
 1                   0.782609  0.666667  0.730519       1
 2                   0.850000  0.774194  0.804762       2
 3                   0.894737  0.800000  0.833333       3
 4                   0.800000  0.689655  0.738095       4  ,
 'train': None}</pre>
<p>We see that this returns a dictionary of dataframes. In this case the
dictionary only has one key which is test.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_performance</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>accuracy</th>
      <th>balanced_accuracy</th>
      <th>precision</th>
      <th>recall</th>
      <th>sensitivity</th>
      <th>specificity</th>
      <th>negative_predictive_value</th>
      <th>f1_score</th>
      <th>auc</th>
      <th>n_fold</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.694444</td>
      <td>0.685065</td>
      <td>0.600000</td>
      <td>0.642857</td>
      <td>0.642857</td>
      <td>0.727273</td>
      <td>0.761905</td>
      <td>0.620690</td>
      <td>0.685065</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.750000</td>
      <td>0.730519</td>
      <td>0.692308</td>
      <td>0.642857</td>
      <td>0.642857</td>
      <td>0.818182</td>
      <td>0.782609</td>
      <td>0.666667</td>
      <td>0.730519</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.805556</td>
      <td>0.804762</td>
      <td>0.750000</td>
      <td>0.800000</td>
      <td>0.800000</td>
      <td>0.809524</td>
      <td>0.850000</td>
      <td>0.774194</td>
      <td>0.804762</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.828571</td>
      <td>0.833333</td>
      <td>0.750000</td>
      <td>0.857143</td>
      <td>0.857143</td>
      <td>0.809524</td>
      <td>0.894737</td>
      <td>0.800000</td>
      <td>0.833333</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.742857</td>
      <td>0.738095</td>
      <td>0.666667</td>
      <td>0.714286</td>
      <td>0.714286</td>
      <td>0.761905</td>
      <td>0.800000</td>
      <td>0.689655</td>
      <td>0.738095</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div><p>From here it is easy to calculate the average cross-validation
performance. Let’s format the result a bit…</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model_performance</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Performance&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;n_fold&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">decimals</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Performance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>accuracy</th>
      <td>0.764</td>
    </tr>
    <tr>
      <th>balanced_accuracy</th>
      <td>0.758</td>
    </tr>
    <tr>
      <th>precision</th>
      <td>0.692</td>
    </tr>
    <tr>
      <th>recall</th>
      <td>0.731</td>
    </tr>
    <tr>
      <th>sensitivity</th>
      <td>0.731</td>
    </tr>
    <tr>
      <th>specificity</th>
      <td>0.785</td>
    </tr>
    <tr>
      <th>negative_predictive_value</th>
      <td>0.818</td>
    </tr>
    <tr>
      <th>f1_score</th>
      <td>0.710</td>
    </tr>
    <tr>
      <th>auc</th>
      <td>0.758</td>
    </tr>
  </tbody>
</table>
</div><p>Let’s see which metrics are implemented…</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">core</span><span class="o">.</span><span class="n">getAvailableDefaultMetrics</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">&#39;binary_classification&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span>
  <span class="s1">&#39;balanced_accuracy&#39;</span><span class="p">,</span>
  <span class="s1">&#39;precision&#39;</span><span class="p">,</span>
  <span class="s1">&#39;recall&#39;</span><span class="p">,</span>
  <span class="s1">&#39;sensitivity&#39;</span><span class="p">,</span>
  <span class="s1">&#39;specificity&#39;</span><span class="p">,</span>
  <span class="s1">&#39;npv&#39;</span><span class="p">,</span>
  <span class="s1">&#39;f1_score&#39;</span><span class="p">,</span>
  <span class="s1">&#39;auc&#39;</span><span class="p">],</span>
 <span class="s1">&#39;regression&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;explained_variance&#39;</span><span class="p">,</span>
  <span class="s1">&#39;mse&#39;</span><span class="p">,</span>
  <span class="s1">&#39;mae&#39;</span><span class="p">,</span>
  <span class="s1">&#39;r2_score&#39;</span><span class="p">,</span>
  <span class="s1">&#39;pearson_correlation&#39;</span><span class="p">]}</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">core</span><span class="o">.</span><span class="n">getDefaultMetrics</span><span class="p">(</span><span class="s1">&#39;binary_classification&#39;</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">Metric</span><span class="p">(</span>
     <span class="n">name</span><span class="o">=</span><span class="n">accuracy</span><span class="p">,</span>
     <span class="n">function_kw</span><span class="o">=</span><span class="p">{},</span>
     <span class="n">multiclass</span><span class="o">=</span><span class="kc">False</span>
 <span class="p">),</span>
 <span class="n">Metric</span><span class="p">(</span>
     <span class="n">name</span><span class="o">=</span><span class="n">balanced_accuracy</span><span class="p">,</span>
     <span class="n">function_kw</span><span class="o">=</span><span class="p">{},</span>
     <span class="n">multiclass</span><span class="o">=</span><span class="kc">False</span>
 <span class="p">)]</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">core</span><span class="o">.</span><span class="n">getDefaultMetrics</span><span class="p">(</span><span class="s1">&#39;regression&#39;</span><span class="p">)[:</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">Metric</span><span class="p">(</span>
     <span class="n">name</span><span class="o">=</span><span class="n">explained_variance</span><span class="p">,</span>
     <span class="n">function_kw</span><span class="o">=</span><span class="p">{},</span>
     <span class="n">multiclass</span><span class="o">=</span><span class="kc">False</span>
 <span class="p">),</span>
 <span class="n">Metric</span><span class="p">(</span>
     <span class="n">name</span><span class="o">=</span><span class="n">mse</span><span class="p">,</span>
     <span class="n">function_kw</span><span class="o">=</span><span class="p">{},</span>
     <span class="n">multiclass</span><span class="o">=</span><span class="kc">False</span>
 <span class="p">)]</span>
</pre></div>
</div>
<p>Now, what if I also want to access the training predictions? By default
the predictions on the data used for training are not calculated. The
rationale of this is to avoid unnecessary calculations when they are not
required. However, we can specify that we want to apply the model on the
training data used in each fold of the cross validation and save the
results of the predictions by calling <strong>core.evalCrossVal</strong> via
<strong>save_train_preds=True</strong>.</p>
<p>Similarly, it is also possible to keep a copy of all the models trained
in each of the folds by means of the parameter <strong>save_models</strong> (by
default this parameter is False).</p>
<blockquote>
<div><p>Here it should be noted that keeping a copy of the models implies a
higher memory usage (similar to keeping a copy of the predictions on
the training set).</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cv_report_2</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">evalCrossVal</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="n">cv_obj</span><span class="p">,</span>
    <span class="n">save_train_preds</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_models</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
<span class="n">cv_report_2</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Performing</span> <span class="n">cross</span><span class="o">-</span><span class="n">validation</span><span class="o">...</span><span class="p">:</span> <span class="mi">5</span><span class="n">it</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">822.77</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">gojo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">CVReport</span> <span class="n">at</span> <span class="mh">0x26c591a3f10</span><span class="o">&gt;</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cv_report_2</span><span class="o">.</span><span class="n">getTrainPredictions</span><span class="p">()</span>  <span class="c1"># access to all the predictions made on the train</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>pred_labels</th>
      <th>true_labels</th>
    </tr>
    <tr>
      <th>n_fold</th>
      <th>indices</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="5" valign="top">0</th>
      <th>0</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th rowspan="5" valign="top">4</th>
      <th>171</th>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>174</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>175</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>176</th>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>177</th>
      <td>1</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>712 rows × 2 columns</p>
</div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cv_report_2</span><span class="o">.</span><span class="n">getTrainedModels</span><span class="p">()</span>   <span class="c1"># It is also easy to access each of the models trained in each of the folds</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="n">SklearnModelWrapper</span><span class="p">(</span>
     <span class="n">base_model</span><span class="o">=</span><span class="s1">&#39;sklearn.svm._classes.SVC&#39;</span><span class="p">,</span>
     <span class="n">model_params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;coef0&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;cache_size&#39;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span> <span class="s1">&#39;class_weight&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">},</span>
     <span class="n">predict_proba</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
     <span class="n">supress_warnings</span><span class="o">=</span><span class="kc">False</span>
 <span class="p">),</span>
 <span class="mi">1</span><span class="p">:</span> <span class="n">SklearnModelWrapper</span><span class="p">(</span>
     <span class="n">base_model</span><span class="o">=</span><span class="s1">&#39;sklearn.svm._classes.SVC&#39;</span><span class="p">,</span>
     <span class="n">model_params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;coef0&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;cache_size&#39;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span> <span class="s1">&#39;class_weight&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">},</span>
     <span class="n">predict_proba</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
     <span class="n">supress_warnings</span><span class="o">=</span><span class="kc">False</span>
 <span class="p">),</span>
 <span class="mi">2</span><span class="p">:</span> <span class="n">SklearnModelWrapper</span><span class="p">(</span>
     <span class="n">base_model</span><span class="o">=</span><span class="s1">&#39;sklearn.svm._classes.SVC&#39;</span><span class="p">,</span>
     <span class="n">model_params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;coef0&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;cache_size&#39;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span> <span class="s1">&#39;class_weight&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">},</span>
     <span class="n">predict_proba</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
     <span class="n">supress_warnings</span><span class="o">=</span><span class="kc">False</span>
 <span class="p">),</span>
 <span class="mi">3</span><span class="p">:</span> <span class="n">SklearnModelWrapper</span><span class="p">(</span>
     <span class="n">base_model</span><span class="o">=</span><span class="s1">&#39;sklearn.svm._classes.SVC&#39;</span><span class="p">,</span>
     <span class="n">model_params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;coef0&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;cache_size&#39;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span> <span class="s1">&#39;class_weight&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">},</span>
     <span class="n">predict_proba</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
     <span class="n">supress_warnings</span><span class="o">=</span><span class="kc">False</span>
 <span class="p">),</span>
 <span class="mi">4</span><span class="p">:</span> <span class="n">SklearnModelWrapper</span><span class="p">(</span>
     <span class="n">base_model</span><span class="o">=</span><span class="s1">&#39;sklearn.svm._classes.SVC&#39;</span><span class="p">,</span>
     <span class="n">model_params</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="s1">&#39;poly&#39;</span><span class="p">,</span> <span class="s1">&#39;degree&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;coef0&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;cache_size&#39;</span><span class="p">:</span> <span class="mi">1000</span><span class="p">,</span> <span class="s1">&#39;class_weight&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">},</span>
     <span class="n">predict_proba</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
     <span class="n">supress_warnings</span><span class="o">=</span><span class="kc">False</span>
 <span class="p">)}</span>
</pre></div>
</div>
<p>We can now calculate the same metrics as before on the test data and the
training data to see how the model behaves.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_performance_2</span> <span class="o">=</span> <span class="n">cv_report_2</span><span class="o">.</span><span class="n">getScores</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">getDefaultMetrics</span><span class="p">(</span><span class="s1">&#39;binary_classification&#39;</span><span class="p">),</span> <span class="n">supress_warnings</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model_performance_2</span>
</pre></div>
</div>
<pre class="literal-block">{'test':    accuracy  balanced_accuracy  precision    recall  sensitivity  specificity   0  0.805556           0.788961   0.769231  0.714286     0.714286     0.863636
 1  0.666667           0.688312   0.550000  0.785714     0.785714     0.590909
 2  0.777778           0.761905   0.769231  0.666667     0.666667     0.857143
 3  0.857143           0.880952   0.736842  1.000000     1.000000     0.761905
 4  0.771429           0.750000   0.750000  0.642857     0.642857     0.857143

    negative_predictive_value  f1_score       auc  n_fold
 0                   0.826087  0.740741  0.788961       0
 1                   0.812500  0.647059  0.688312       1
 2                   0.782609  0.714286  0.761905       2
 3                   1.000000  0.848485  0.880952       3
 4                   0.782609  0.692308  0.750000       4  ,
 'train':    accuracy  balanced_accuracy  precision    recall  sensitivity  specificity   0  0.746479           0.742002   0.672131  0.719298     0.719298     0.764706
 1  0.795775           0.794737   0.725806  0.789474     0.789474     0.800000
 2  0.760563           0.761836   0.671875  0.767857     0.767857     0.755814
 3  0.755245           0.752142   0.677419  0.736842     0.736842     0.767442
 4  0.769231           0.763770   0.700000  0.736842     0.736842     0.790698

    negative_predictive_value  f1_score       auc  n_fold
 0                   0.802469  0.694915  0.742002       0
 1                   0.850000  0.756303  0.794737       1
 2                   0.833333  0.716667  0.761836       2
 3                   0.814815  0.705882  0.752142       3
 4                   0.819277  0.717949  0.763770       4  }</pre>
<p>We see that the model behaves similarly in training and testing which is
indicating that the model is not overfitting (<strong>we will see later what
is actually happening since the model performing poorly</strong>).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model_performance_2</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Performance (test)&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;n_fold&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">decimals</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model_performance_2</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Performance (train)&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;n_fold&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">decimals</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Performance (test)</th>
      <th>Performance (train)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>accuracy</th>
      <td>0.776</td>
      <td>0.765</td>
    </tr>
    <tr>
      <th>balanced_accuracy</th>
      <td>0.774</td>
      <td>0.763</td>
    </tr>
    <tr>
      <th>precision</th>
      <td>0.715</td>
      <td>0.689</td>
    </tr>
    <tr>
      <th>recall</th>
      <td>0.762</td>
      <td>0.750</td>
    </tr>
    <tr>
      <th>sensitivity</th>
      <td>0.762</td>
      <td>0.750</td>
    </tr>
    <tr>
      <th>specificity</th>
      <td>0.786</td>
      <td>0.776</td>
    </tr>
    <tr>
      <th>negative_predictive_value</th>
      <td>0.841</td>
      <td>0.824</td>
    </tr>
    <tr>
      <th>f1_score</th>
      <td>0.729</td>
      <td>0.718</td>
    </tr>
    <tr>
      <th>auc</th>
      <td>0.774</td>
      <td>0.763</td>
    </tr>
  </tbody>
</table>
</div><p>Furthremore, let’s take advantage of the fact that we have saved the
models to take a look at the different support vectors.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># First, let&#39;s make a two-dimensional projection of the data to facilitate visualization.</span>
<span class="n">tsne_projection</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">perplexity</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2024</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">tsne_projection</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">tsne_projection</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;emb_1&#39;</span><span class="p">,</span> <span class="s1">&#39;emb_2&#39;</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trained_models</span> <span class="o">=</span> <span class="n">cv_report_2</span><span class="o">.</span><span class="n">getTrainedModels</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trained_models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">support_</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([</span>  <span class="mi">4</span><span class="p">,</span>  <span class="mi">15</span><span class="p">,</span>  <span class="mi">16</span><span class="p">,</span>  <span class="mi">18</span><span class="p">,</span>  <span class="mi">31</span><span class="p">,</span>  <span class="mi">32</span><span class="p">,</span>  <span class="mi">34</span><span class="p">,</span> <span class="mi">103</span><span class="p">,</span> <span class="mi">104</span><span class="p">,</span> <span class="mi">105</span><span class="p">,</span> <span class="mi">106</span><span class="p">,</span> <span class="mi">107</span><span class="p">,</span> <span class="mi">108</span><span class="p">,</span>
       <span class="mi">109</span><span class="p">,</span> <span class="mi">110</span><span class="p">,</span> <span class="mi">111</span><span class="p">,</span> <span class="mi">112</span><span class="p">,</span> <span class="mi">114</span><span class="p">,</span> <span class="mi">115</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">117</span><span class="p">,</span> <span class="mi">118</span><span class="p">,</span> <span class="mi">119</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">121</span><span class="p">,</span> <span class="mi">122</span><span class="p">,</span>
       <span class="mi">123</span><span class="p">,</span> <span class="mi">125</span><span class="p">,</span> <span class="mi">126</span><span class="p">,</span> <span class="mi">127</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">129</span><span class="p">,</span> <span class="mi">130</span><span class="p">,</span> <span class="mi">131</span><span class="p">,</span> <span class="mi">132</span><span class="p">,</span> <span class="mi">133</span><span class="p">,</span> <span class="mi">134</span><span class="p">,</span> <span class="mi">135</span><span class="p">,</span> <span class="mi">136</span><span class="p">,</span>
       <span class="mi">137</span><span class="p">,</span> <span class="mi">138</span><span class="p">,</span> <span class="mi">139</span><span class="p">,</span> <span class="mi">141</span><span class="p">,</span>  <span class="mi">46</span><span class="p">,</span>  <span class="mi">47</span><span class="p">,</span>  <span class="mi">48</span><span class="p">,</span>  <span class="mi">49</span><span class="p">,</span>  <span class="mi">50</span><span class="p">,</span>  <span class="mi">52</span><span class="p">,</span>  <span class="mi">53</span><span class="p">,</span>  <span class="mi">54</span><span class="p">,</span>  <span class="mi">55</span><span class="p">,</span>
        <span class="mi">56</span><span class="p">,</span>  <span class="mi">57</span><span class="p">,</span>  <span class="mi">58</span><span class="p">,</span>  <span class="mi">59</span><span class="p">,</span>  <span class="mi">60</span><span class="p">,</span>  <span class="mi">62</span><span class="p">,</span>  <span class="mi">63</span><span class="p">,</span>  <span class="mi">65</span><span class="p">,</span>  <span class="mi">66</span><span class="p">,</span>  <span class="mi">67</span><span class="p">,</span>  <span class="mi">68</span><span class="p">,</span>  <span class="mi">69</span><span class="p">,</span>  <span class="mi">70</span><span class="p">,</span>
        <span class="mi">71</span><span class="p">,</span>  <span class="mi">72</span><span class="p">,</span>  <span class="mi">73</span><span class="p">,</span>  <span class="mi">74</span><span class="p">,</span>  <span class="mi">77</span><span class="p">,</span>  <span class="mi">78</span><span class="p">,</span>  <span class="mi">79</span><span class="p">,</span>  <span class="mi">81</span><span class="p">,</span>  <span class="mi">82</span><span class="p">,</span>  <span class="mi">83</span><span class="p">,</span>  <span class="mi">85</span><span class="p">,</span>  <span class="mi">86</span><span class="p">,</span>  <span class="mi">88</span><span class="p">,</span>
        <span class="mi">89</span><span class="p">,</span>  <span class="mi">90</span><span class="p">,</span>  <span class="mi">91</span><span class="p">,</span>  <span class="mi">93</span><span class="p">,</span>  <span class="mi">94</span><span class="p">,</span>  <span class="mi">96</span><span class="p">,</span>  <span class="mi">97</span><span class="p">,</span> <span class="mi">102</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">tsne_projection</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="s1">&#39;emb_1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">tsne_projection</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="s1">&#39;emb_2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#52BE80&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Positive class&#39;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span>
<span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">tsne_projection</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s1">&#39;emb_1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">tsne_projection</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s1">&#39;emb_2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#F39C12&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Negative class&#39;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span>
<span class="p">)</span>

<span class="c1"># access to the support vectors of the first model</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">tsne_projection</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">trained_models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">support_</span><span class="p">][</span><span class="s1">&#39;emb_1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">tsne_projection</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">trained_models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">support_</span><span class="p">][</span><span class="s1">&#39;emb_2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Supports (model 1)&#39;</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;bottom&#39;</span><span class="p">]:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;t-SNE (2)&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;t-SNE (1)&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Projection of the support vectors&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/Example_1_Model_evaluation_by_cross_validation_47_0.png" src="../_images/Example_1_Model_evaluation_by_cross_validation_47_0.png" />
<p>No doubt something strange is going on with the data… what could it be?
<strong>THAT WE HAVE FORGOTTEN TO STANDARDIZE THEM!!!</strong></p>
<p>To standardize the data during cross validation using the statistics of
the training data to prevent any data leakage we can make use of the
<strong>interfaces.SKLearnTransformWrapper</strong> interface. Let us now look at the
above example by standardizing the data to z-scores based on the
training statistics.</p>
<blockquote>
<div><p><strong>Note</strong>: any type of transformation can be implemented through the
<strong>interfaces.Transform</strong> or <strong>interfaces.SKLearnTransformWrapper</strong>
interfaces (e.g. a feature selection or any other type of
transformation).</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">zscores_scaler</span> <span class="o">=</span> <span class="n">interfaces</span><span class="o">.</span><span class="n">SKLearnTransformWrapper</span><span class="p">(</span><span class="n">transform_class</span><span class="o">=</span><span class="n">StandardScaler</span><span class="p">)</span>
<span class="n">zscores_scaler</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">SKLearnTransformWrapper</span><span class="p">(</span>
    <span class="n">base_transform</span><span class="o">=</span><span class="s1">&#39;sklearn.preprocessing._data.StandardScaler&#39;</span><span class="p">,</span>
    <span class="n">transform_params</span><span class="o">=</span><span class="p">{}</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cv_report_3</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">evalCrossVal</span><span class="p">(</span>
    <span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="n">cv_obj</span><span class="p">,</span>
    <span class="n">save_train_preds</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">save_models</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transforms</span><span class="o">=</span><span class="p">[</span><span class="n">zscores_scaler</span><span class="p">]</span>     <span class="c1"># we can provide he transforms using the `transform` parameter</span>
<span class="p">)</span>
<span class="n">cv_report_3</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Performing</span> <span class="n">cross</span><span class="o">-</span><span class="n">validation</span><span class="o">...</span><span class="p">:</span> <span class="mi">5</span><span class="n">it</span> <span class="p">[</span><span class="mi">00</span><span class="p">:</span><span class="mi">00</span><span class="p">,</span> <span class="mf">830.52</span><span class="n">it</span><span class="o">/</span><span class="n">s</span><span class="p">]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">gojo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">report</span><span class="o">.</span><span class="n">CVReport</span> <span class="n">at</span> <span class="mh">0x26c735cde10</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>Let’s recalculate the performance as before…</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_performance_3</span> <span class="o">=</span> <span class="n">cv_report_3</span><span class="o">.</span><span class="n">getScores</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">getDefaultMetrics</span><span class="p">(</span><span class="s1">&#39;binary_classification&#39;</span><span class="p">),</span> <span class="n">supress_warnings</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model_performance_3</span><span class="p">[</span><span class="s1">&#39;test&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Performance (test)&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;n_fold&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">decimals</span><span class="o">=</span><span class="mi">3</span><span class="p">),</span>
    <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model_performance_3</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Performance (train)&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;n_fold&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">decimals</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Performance (test)</th>
      <th>Performance (train)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>accuracy</th>
      <td>0.983</td>
      <td>0.987</td>
    </tr>
    <tr>
      <th>balanced_accuracy</th>
      <td>0.981</td>
      <td>0.984</td>
    </tr>
    <tr>
      <th>precision</th>
      <td>0.985</td>
      <td>1.000</td>
    </tr>
    <tr>
      <th>recall</th>
      <td>0.971</td>
      <td>0.968</td>
    </tr>
    <tr>
      <th>sensitivity</th>
      <td>0.971</td>
      <td>0.968</td>
    </tr>
    <tr>
      <th>specificity</th>
      <td>0.991</td>
      <td>1.000</td>
    </tr>
    <tr>
      <th>negative_predictive_value</th>
      <td>0.983</td>
      <td>0.980</td>
    </tr>
    <tr>
      <th>f1_score</th>
      <td>0.978</td>
      <td>0.984</td>
    </tr>
    <tr>
      <th>auc</th>
      <td>0.981</td>
      <td>0.984</td>
    </tr>
  </tbody>
</table>
</div><p>As you can see now if we have a good performance, it is very important
that for distance-based models such as SVMs we <strong>standardize the
data!!!</strong></p>
<p>Let’s represent again the support vectors of the first model…</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># access to trained models</span>
<span class="n">trained_models</span> <span class="o">=</span> <span class="n">cv_report_3</span><span class="o">.</span><span class="n">getTrainedModels</span><span class="p">()</span>

<span class="c1"># standardization of all data to z-scores to recalculate the t-SNE projection</span>
<span class="n">zscores_scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">zscores_X</span> <span class="o">=</span> <span class="n">zscores_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">tsne_projection</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">perplexity</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2024</span><span class="p">)</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">zscores_X</span><span class="p">)</span>
<span class="n">tsne_projection</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">tsne_projection</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;emb_1&#39;</span><span class="p">,</span> <span class="s1">&#39;emb_2&#39;</span><span class="p">])</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">tsne_projection</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="s1">&#39;emb_1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">tsne_projection</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="s1">&#39;emb_2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#52BE80&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Positive class&#39;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span>
<span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">tsne_projection</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s1">&#39;emb_1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">tsne_projection</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s1">&#39;emb_2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#F39C12&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Negative class&#39;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span>
<span class="p">)</span>

<span class="c1"># access to the support vectors of the first model</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">tsne_projection</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">trained_models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">support_</span><span class="p">][</span><span class="s1">&#39;emb_1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">tsne_projection</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">trained_models</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">support_</span><span class="p">][</span><span class="s1">&#39;emb_2&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Supports (model 1)&#39;</span><span class="p">,</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;bottom&#39;</span><span class="p">]:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;grey&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;t-SNE (2)&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;t-SNE (1)&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Projection of the support vectors&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/Example_1_Model_evaluation_by_cross_validation_54_0.png" src="../_images/Example_1_Model_evaluation_by_cross_validation_54_0.png" />
<p><strong>We have now been able to see that the support vectors make much more
sense than before, and there are also fewer of them, which is a sign
that the model is not overfitting.</strong></p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../index.html" class="btn btn-neutral float-left" title="GoJo - Make Machine/Deep Learning pipelines simple" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../gojo.core.html" class="btn btn-neutral float-right" title="gojo.core package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Fernando García Gutiérrez.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>